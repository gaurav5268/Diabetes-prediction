# Diabetes Prediction Machine Learning Project

A Machine Learningâ€“based web application that predicts the probability of Diabetes
using patient health parameters such as Glucose level, BMI, Insulin, Age, etc.

The project includes:

âœ” End-to-end ML pipeline  
âœ” Feature Engineering  
âœ” Model Training & Hyperparameter Tuning  
âœ” Threshold Optimization (Recall-Focused)  
âœ” MLflow Experiment Tracking  
âœ” Flask API Deployment  
âœ” Docker Support  
âœ” Frontend UI with live inference  

---

## Live Demo

ğŸ”— **App URL**  
[ https://diabetes-prediction-laim.onrender.com/ ]

---

## Problem Statement

Early prediction of diabetes can help:

- Reduce severe complications  
- Improve treatment planning  
- Support medical diagnosis

This project predicts whether a person is:

ğŸŸ¢ Non-Diabetic  
ğŸ”´ Diabetic (High Risk)

The model is optimized to **increase Recall**, ensuring fewer false negatives.

---

## Dataset

Dataset â€” PIMA Indians Diabetes Dataset

Features used:

| Feature | Description |
|--------|----------|
| Pregnancies | Number of pregnancies |
| Glucose | Plasma glucose concentration |
| BloodPressure | Diastolic blood pressure |
| SkinThickness | Triceps skin fold thickness |
| Insulin | Serum insulin |
| BMI | Body Mass Index |
| DiabetesPedigreeFunction | Genetic risk score |
| Age | Age in years |

Additional engineered features:

- Age Group Buckets  
- BMI Risk Category  
- Glucose Risk Category  
- BMI Ã— Age Interaction  
- Glucose Ã— Pregnancy Interaction  
- DPF Scaled Feature  

---

## Machine Learning Model Development & Selection
- Step 1 â€” Trained Multiple Base Models

The project started by training and evaluating multiple baseline machine learning models:

        Model	Description
        Logistic Regression	Simple & interpretable baseline
        KNN	Distance-based learner
        Decision Tree	Rule-based classifier
        Random Forest	Bagging ensemble
        Gradient Boosting	Sequential boosting
        XGBoost	Optimized gradient boosting
        LightGBM	Fast & memory-efficient boosting
        SVM	Margin-based classifier

All models were evaluated using:

        Accuracy

        Recall (priority metric)

        F1-Score

        Cross-Validation score

Step 2 â€” Shortlisted Top Performing Models

        After evaluation of all base models, the top 3 performers were shortlisted:

        Selected Model	Reason
        Random Forest	Strong baseline & robust
        Gradient Boosting	Good generalization
        LightGBM	Best recall & stability

        These were further improved using:

        Hyperparameter tuning

        Cross-validation

        Threshold tuning

## Step 3 â€” Business / Medical Objective

        Diabetes prediction is a health-risk classification problem.

        In real healthcare:

        âš  Missing a diabetic patient (False Negative)
        is more dangerous than giving an early alert (False Positive)

        Therefore, the project prioritizes:

            âœ” Higher Recall (catch risk cases)
            âœ” Lower False Negatives
            âœ” Early-risk detection

hreshold Optimization

Instead of using the default threshold 0.50,
multiple probability thresholds were tested:

0.20 â†’ 0.25 â†’ 0.30 â†’ 0.35 â†’ 0.40 â†’ 0.50


The goal was to find a balance between:

    Recall (medical safety)

    Accuracy

F1 Score

Threshold = 0.20 gave the best medical value

It helps:

    âœ” Detect more potential diabetic cases early
    âœ” Reduce false-negative risk
    âœ” Improve recall while keeping accuracy acceptable''

Final Selected Model
- Final Model   : LightGBM Classifier
- Selection Base: Recall + Stability + Performance
- Threshold     : 0.20
- Decision Rule : Predict Diabetic if Probability â‰¥ 0.20

## Why LightGBM was chosen

- Best Recall performance

- Consistent results across runs

- Works well with engineered features

- Fast inference suitable for deployment

- Better handling of feature interactions

## Tech Stack

**Languages**
- Python

**Machine Learning**
- Scikit-Learn
- LightGBM
- Random Forest
- Gradient Boosting

**Experiment Tracking**
- MLflow

**Deployment**
- Flask API
- HTML + CSS + JS Frontend
- Docker Support

---

## Project Architecture

```
data/
models/
 â””â”€â”€ ml_model.pkl
notebooks/
src/
app.py
static/
templates/
README.md
requirements.txt
Dockerfile
```

---

## Installation & Setup

### ğŸ”¹ 1ï¸ Create Virtual Environment

```bash
python -m venv ml_env
source ml_env/Scripts/activate   # Windows
```

---

### ğŸ”¹ 2ï¸ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### ğŸ”¹ 3ï¸ Run Flask App

```bash
python app.py
```

App runs on:

```
http://127.0.0.1:5000
```

---

## Model Training Summary

Base models tested:

- Logistic Regression
- Random Forest
- Gradient Boosting
- LightGBM
- XGBoost
- SVM
- KNN

Threshold tuning performed to maximize Recall.

**Best Performing Model**

âœ” LightGBM  
âœ” Recall-optimized  
âœ” Threshold = 0.2  

---

## ğŸ§¾ API Usage

### ğŸ”¹ Endpoint

```
POST /predict
```

### ğŸ”¹ Sample Request

```json
{
  "Pregnancies": 2,
  "Glucose": 155,
  "BloodPressure": 82,
  "SkinThickness": 32,
  "Insulin": 140,
  "BMI": 33.2,
  "DiabetesPedigreeFunction": 0.65,
  "Age": 45
}
```

### ğŸ”¹ Sample Response

```json
{
  "prediction": 1,
  "probability": 0.82,
  "threshold": 0.2,
  "result": "Diabetic"
}
```


---

**Gaurav Chauhan**  